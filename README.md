# Facial Expression Recognition using CNN on FER2013

This project implements a **Facial Expression Recognition (FER)** system using the **FER2013** dataset. The model uses a **Convolutional Neural Network (CNN)** to classify facial images into one of seven emotion categories: Angry, Disgust, Fear, Happy, Sad, Surprise, and Neutral.

---

## ğŸ§  Model Overview

The neural network is built using **TensorFlow/Keras** and trained on grayscale images of faces (48x48 pixels). It is designed to recognize facial emotions with a deep learning architecture that includes convolutional, pooling, normalization, and dropout layers.

---

## ğŸ“ Dataset

- **Source:** `fer2013.csv`
- **Size:** 35,887 images
- **Features:**
  - `emotion`: Emotion label (0â€“6)
  - `pixels`: Flattened grayscale pixel values
  - `Usage`: One of `Training`, `PublicTest`, or `PrivateTest`

---

## âš™ï¸ Preprocessing

1. **Pixels** are converted into 48x48 grayscale image arrays.
2. Images are normalized (scaled between 0 and 1).
3. Emotion labels are one-hot encoded.
4. Dataset is split into:
   - `Training`: Model fitting
   - `PublicTest`: Validation
   - `PrivateTest`: Testing

---

## ğŸ—ï¸ Model Architecture

```text
Input: 48x48x1 grayscale image

Conv2D (32 filters, 3x3) â†’ BatchNorm â†’ MaxPooling â†’ Dropout
Conv2D (64 filters, 5x5) â†’ BatchNorm â†’ MaxPooling â†’ Dropout
Flatten
Dense (128 units, ReLU) â†’ Dropout
Dense (7 units, Softmax)
```

- **Loss Function:** Categorical Crossentropy
- **Optimizer:** Adam
- **Metrics:** Accuracy

---

## ğŸ‹ï¸ Training

- **Epochs:** 30
- **Batch Size:** 128
- **Callbacks:**
  - `EarlyStopping`: Stops if no improvement in validation loss
  - `ModelCheckpoint`: Saves best model weights based on validation accuracy

---

## ğŸ“‰ Evaluation

```python
test_loss, test_accuracy = model.evaluate(pic_test, label_test)
```

- **Test Accuracy:** ~15% (may vary, room for improvement through tuning or augmentation)

---

## ğŸ“Š Training History

Visualizations of accuracy and loss over epochs for both training and validation sets.

```python
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
```

---

## ğŸ” Making Predictions

```python
import cv2
new_image = cv2.imread('sad_face.jpeg')
new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2GRAY)
new_image = cv2.resize(new_image, (48, 48))
new_image = new_image / 255.0
new_image = new_image.reshape(1, 48, 48, 1)
prediction = model.predict(new_image)
```

- Predicted label is mapped back to:
  ```python
  emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
  ```

---

## âœ… Requirements

```bash
tensorflow
numpy
pandas
matplotlib
opencv-python
```

Install with:

```bash
pip install tensorflow numpy pandas matplotlib opencv-python
```

---

## ğŸš€ Future Improvements

- Data Augmentation to improve generalization
- Hyperparameter tuning
- More complex architectures (e.g., ResNet, EfficientNet)
- Real-time webcam emotion detection

---
